{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _E. coli_ ampicillin analysis\n",
    "\n",
    "This notebook aims to analyze the ampicillin resistance in _E. coli_ bacteria.\n",
    "\n",
    "* import modules for cluster, data, and network analysis\n",
    "* load the data\n",
    "* perform pairwise associations\n",
    "* perform ML approaches\n",
    "* construct the network \n",
    "* analyze the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Essentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast # --for string to list conversion\n",
    "import os\n",
    "import sys\n",
    "from IPython.display import display\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import mutual_info_score\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import fisher_exact\n",
    "from scipy.stats import f_oneway\n",
    "from statsmodels.stats.multitest import multipletests \n",
    "\n",
    "os.chdir(os.path.expanduser('~/capstone-project'))\n",
    "sys.path.append('src')\n",
    "\n",
    "import cluster_analysis\n",
    "import gene_associations\n",
    "import network_construction\n",
    "import network_analysis\n",
    "import cluster_analysis\n",
    "\n",
    "species='Escherichia_coli'; drug = 'ampicillin'\n",
    "\n",
    "\n",
    "def apply_FDR_correction(p_val_dict):\n",
    "    '''\n",
    "    takes a dict of pval as vals and returns a dict of corrected p vals based on FDR (benjamini-hochberg)\n",
    "\n",
    "    param:\n",
    "    -------\n",
    "    - p_val_dict: dict\n",
    "\n",
    "    return:\n",
    "    -------\n",
    "    - corrected_p_val_dict: dict\n",
    "    '''\n",
    "    \n",
    "    p_values_list = list(p_val_dict.values())\n",
    "\n",
    "    _, p_values_corrected, _, _ = multipletests(p_values_list, method='fdr_bh')\n",
    "    corrected_p_val_dict = dict(zip(p_val_dict.keys(), p_values_corrected))\n",
    "\n",
    "    return corrected_p_val_dict\n",
    "\n",
    "def flip_dict(d):\n",
    "    '''\n",
    "    flips a dict\n",
    "    '''\n",
    "    return {v: k for k, v in d.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "- presence absence data (filtered SxG)\n",
    "- processed phenotypic readings\n",
    "- ARGs for the dfrug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rayane/miniconda3/lib/python3.12/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(506, 18876)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "presence_path = f'data/presence_matrices/{species}_filtered_GxS.csv' #needed later on for resistance lors\n",
    "presence_df = pd.read_csv(presence_path, index_col=0)\n",
    "pheno_path = f'data/processed_phenotypes/{species}_{drug}.csv' \n",
    "\n",
    "#  ----------------- cluster info -----------------\n",
    "cluster_info_df = pd.read_csv(f'data/clusters/{species}_cluster_info_filtered.csv', index_col=0)\n",
    "\n",
    "# ----------------- LOR of resistance -----------------\n",
    "lor_resistance_scores = cluster_analysis.get_cluster_resistance_LOR(presence_df, pheno_path)\n",
    "lor_resistance_scores_dict =lor_resistance_scores.to_dict()['log_odds'] # -- we want it as cluster attributes later on\n",
    "\n",
    "# ----------------- ARGs -----------------\n",
    "ARG_df = pd.read_csv(f'data/ARG/{species}_ARG_sp_drugs_products.csv', index_col=0)\n",
    "ARG_products_list = ast.literal_eval(ARG_df.loc[drug].tolist()[0]) #bcs its saved as a '['a','b']' str instead of a list, and tolist() puts this str in a one item list\n",
    "\n",
    "# ----------------- SxG presence -----------------\n",
    "X_df = pd.read_csv(f'data/presence_matrices/{species}_filtered_SxG.csv', index_col=0) \n",
    "\n",
    "features = X_df.columns.tolist()\n",
    "products_list = [cluster_analysis.transform_cluster_to_product(cluster) for cluster in features]\n",
    "ARG_products_list_in_pan = [p for p in products_list if p[:-2] in ARG_products_list]\n",
    "\n",
    "# ----------------- phenotypes -----------------\n",
    "pheno_df= pd.read_csv(f'data/processed_phenotypes/{species}_{drug}.csv', index_col=0)\n",
    "y_df=pheno_df\n",
    "y_df.index = y_df.index.astype('float')\n",
    "\n",
    "y_df = y_df.sort_index()\n",
    "\n",
    "y_indices=list(y_df.index)\n",
    "\n",
    "# ----------------- intersection to created a labeled matrix -----------------\n",
    "\n",
    "X_df = X_df.sort_index()\n",
    "y_df = y_df.sort_index()\n",
    "\n",
    "y_indices=list(y_df.index)\n",
    "X_indices=list(X_df.index)\n",
    "\n",
    "intersection = [i for i in y_indices if i in X_indices]\n",
    "y_df = y_df.loc[intersection]\n",
    "X_df = X_df.loc[intersection]\n",
    "\n",
    "X_df = X_df.sort_index()\n",
    "y_df = y_df.sort_index() # -- just making sure bcs im paranoid :)\n",
    "\n",
    "X = X_df.values\n",
    "y = y_df.values\n",
    "\n",
    "\n",
    "labeled_matrix = pd.concat([X_df, y_df], axis=1)\n",
    "labeled_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pairwise associations\n",
    "\n",
    "### Stats\n",
    "- Mutual information\n",
    "- $X^2$ test\n",
    "- one-way ANOVA\n",
    "\n",
    "### ML\n",
    "- 200 SVM ensemble (lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_scores={}; chi2_scores={}; fisher_scores={}; anova_scores={}\n",
    "chi2_pvals={}; anova_pvals={}\n",
    "chi2_pvals_corrected={}; anova_pvals_corrected={}\n",
    "\n",
    "# -- Mutual Information\n",
    "for col in labeled_matrix.columns[:-1]:\n",
    "    mi_scores[col]=mutual_info_score(labeled_matrix[col], labeled_matrix['SIR'])\n",
    "mi_ranked=sorted(mi_scores, key=mi_scores.get, reverse=True)\n",
    "\n",
    "# -- Chi2\n",
    "for col in labeled_matrix.columns[:-1]:\n",
    "    \n",
    "    contingency_table = pd.crosstab(labeled_matrix[col], labeled_matrix['SIR'])\n",
    "    chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "    chi2_scores[col] = chi2\n",
    "    chi2_pvals[col] = p\n",
    "chi2_pvals_corrected = apply_FDR_correction(chi2_pvals)\n",
    "chi2_ranked=sorted(chi2_pvals_corrected, key=chi2_scores.get, reverse=False) # ranked based on smallest corrrected pval\n",
    "\n",
    "# -- one way ANOVA\n",
    "for col in labeled_matrix.columns[:-1]:\n",
    "    f_statistic, p_value = f_oneway(labeled_matrix[col], labeled_matrix['SIR'])\n",
    "\n",
    "    anova_scores[col] = f_statistic\n",
    "    anova_pvals[col] = p_value\n",
    "anova_pvals_corrected = apply_FDR_correction(anova_pvals)\n",
    "anova_ranked=sorted(anova_pvals_corrected, key=anova_scores.get, reverse=False) # pcal ranking as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- model training\n",
    "n_models = 200\n",
    "n_samples = int(0.8 * len(X)) # boostrap on 80% of the data\n",
    "\n",
    "models=[]\n",
    "for i in range(n_models): # this should give the same 200 models when retrained \n",
    "    # X_boot, y_boot = resample(X, y, n_samples=n_samples, random_state=i)\n",
    "    model=SGDClassifier(loss='hinge', penalty= 'l1', max_iter=1000, tol=1e-3)\n",
    "    model.fit(X, y.ravel())\n",
    "    models.append(model)\n",
    "\n",
    "weights = np.zeros((X.shape[1], n_models))\n",
    "for i, m in enumerate(models):\n",
    "    weights[:,i] = m.coef_[0]\n",
    "\n",
    "avg_coef = np.mean(weights, axis=1)\n",
    "avg_of_avg = np.mean(np.abs(avg_coef))\n",
    "features = X_df.columns.tolist()\n",
    "\n",
    "avg_coef_dict = dict(zip(features, avg_coef))\n",
    "\n",
    "weights_df = pd.DataFrame(weights, index=features)\n",
    "weights_df.columns = [f'model_{i+1}' for i in range(n_models)]\n",
    "\n",
    "print(f'-- avg of the absolute value of the feature s coef avgs is {avg_of_avg}')\n",
    "\n",
    "# ------------- computing the SVM features scores -------------\n",
    "\n",
    "SVM_scores = avg_coef_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_scores = {}\n",
    "for col in labeled_matrix.columns[:-1]:\n",
    "    mi_scores[col]=mutual_info_score(labeled_matrix[col], labeled_matrix['SIR'])\n",
    "\n",
    "mi_ranked_ARGS = gene_associations.get_ranked_ARGs_from_association(mi_scores, ARG_products_list, n=1000)\n",
    "mi_ranked_ARGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_scores = {}; p_values={}\n",
    "for col in labeled_matrix.columns[:-1]:\n",
    "    \n",
    "    contingency_table = pd.crosstab(labeled_matrix[col], labeled_matrix['SIR'])\n",
    "    chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "    chi2_scores[col] = chi2\n",
    "    p_values[col] = p\n",
    "\n",
    "# -- benjamini hochberg correction\n",
    "p_values_corrected_dict = apply_FDR_correction(p_values)\n",
    "\n",
    "chi2_ranked_ARGS = gene_associations.get_ranked_ARGs_from_association(p_values_corrected_dict, ARG_products_list, n=1000, sort_reverse=False)\n",
    "chi2_ranked_ARGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_scores = {}; p_values={}\n",
    "for col in labeled_matrix.columns[:-1]:\n",
    "    f_statistic, p_value = f_oneway(labeled_matrix[col], labeled_matrix['SIR'])\n",
    "\n",
    "    anova_scores[col] = f_statistic\n",
    "    p_values[col] = p_value\n",
    "\n",
    "# -- corr\n",
    "p_values_corrected_dict = apply_FDR_correction(p_values)\n",
    "\n",
    "anova_ranked_ARGS = gene_associations.get_ranked_ARGs_from_association(p_values_corrected_dict, ARG_products_list, n=1000, sort_reverse=False)\n",
    "anova_ranked_ARGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lor_resistance_scores = cluster_analysis.get_cluster_resistance_LOR(presence_df, pheno_path)\n",
    "lor_resistance_scores_dict =lor_resistance_scores.to_dict()['log_odds']\n",
    "\n",
    "lor_ranked_ARGS = gene_associations.get_ranked_ARGs_from_association(lor_resistance_scores_dict, ARG_products_list, n =1000)\n",
    "lor_ranked_ARGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_coef_dict = {k: v for k, v in avg_coef_dict.items() if abs(v) > avg_of_avg}\n",
    "print(f'-- number of genes having abs avg coef higher than {avg_of_avg} is {len(avg_coef_dict)} (will be taken as nodes)')\n",
    "\n",
    "print('-- querying for ARGs amongs these nodes:')\n",
    "temp_ARG = gene_associations.get_ranked_ARGs_from_association(avg_coef_dict, ARG_products_list, n=len(avg_coef_dict))\n",
    "temp_ARG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- keeping important features (those with avg coef higher than 1)\n",
    "\n",
    "# avg_coef_dict_filtered = {k: v for k, v in avg_coef_dict.items() if abs(v) > 1}\n",
    "# print(f'-- number of genes having abs avg coef higher than 1 is {len(avg_coef_dict_filtered)} (will be taken as nodes)')\n",
    "# print('-- querying for ARGs amongs these nodes:')\n",
    "# temp_ARG = gene_associations.get_ranked_ARGs_from_association(avg_coef_dict_filtered, ARG_products_list, n=len(avg_coef_dict_filtered))\n",
    "# temp_ARG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_clusters = list(avg_coef_dict.keys())\n",
    "weights_df = weights_df.loc[node_clusters]\n",
    "weights_df = weights_df.T #-- genes as cols\n",
    "\n",
    "corr_SVM = weights_df.corr()\n",
    "\n",
    "gene_pairs_corr = []; t=0.5; SVM_G = nx.Graph()\n",
    "\n",
    "for i in range(corr_SVM.shape[0]):\n",
    "    for j in range(i+1, corr_SVM.shape[0]):\n",
    "        if abs(corr_SVM.iloc[i,j]) > t:\n",
    "            gene_pairs_corr.append((corr_SVM.index[i], corr_SVM.index[j], corr_SVM.iloc[i,j]))\n",
    "            SVM_G.add_edge(corr_SVM.index[i], corr_SVM.index[j], weight=corr_SVM.iloc[i,j])\n",
    "\n",
    "nx.write_graphml(SVM_G,f'data/temp/{species}_{drug}_SVM_{t}.graphml')\n",
    "del corr_SVM # (to save some space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_analysis.plot_degree_distribution(SVM_G)\n",
    "network_analysis.plot_log_log(SVM_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- breakpoint, run this if wanna proceed construction from middle\n",
    "t=0.5\n",
    "SVM_G = nx.read_graphml(f'data/temp/{species}_{drug}_SVM_{t}.graphml')\n",
    "gene_pairs_corr = list(SVM_G.edges(data=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_construction.set_pheno_path(pheno_path)\n",
    "LOR_coocc=network_construction.compute_cooccurence_LOR(gene_pairs_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = network_construction.construct_network(LOR_coocc)\n",
    "nx.write_graphml(G,f'results/Escherichia_coli_ampicillin/{species}_{drug}_LOR.graphml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G = nx.read_graphml(f'results/Escherichia_coli_ampicillin/{species}_{drug}_LOR_0.5.graphml')\n",
    "G = cluster_analysis.set_node_attributes_by_cluster(cluster_info_df, G)\n",
    "nx.set_node_attributes(G, lor_resistance_scores_dict, f'log_odds_{drug}_resistance')\n",
    "nx.write_graphml(G,f'results/Escherichia_coli_ampicillin/{species}_{drug}_LOR_annotated.graphml')\n",
    "nodes = list(G.nodes)\n",
    "\n",
    "network_analysis.plot_degree_distribution(G)\n",
    "network_analysis.plot_log_log(G)\n",
    "stats =network_analysis.compute_network_stats(G, 'LOR co-occurence for nodes above avg_avg_coef')\n",
    "\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_mi = gene_associations.get_ranked_ARGs_from_association(mi_scores, ARG_products_list, n=1000)\n",
    "ranked_chi2 = gene_associations.get_ranked_ARGs_from_association(chi2_pvals_corrected, ARG_products_list, n=1000, sort_reverse=False)\n",
    "ranked_anova = gene_associations.get_ranked_ARGs_from_association(anova_pvals_corrected, ARG_products_list, n=1000, sort_reverse=False)\n",
    "ranked_svm= gene_associations.get_ranked_ARGs_from_association(SVM_scores, ARG_products_list, n=1000)\n",
    "\n",
    "ranked_mi = flip_dict(ranked_mi)\n",
    "ranked_chi2 = flip_dict(ranked_chi2)\n",
    "ranked_anova = flip_dict(ranked_anova)\n",
    "ranked_svm = flip_dict(ranked_svm)\n",
    "\n",
    "index = ARG_products_list_in_pan\n",
    "pairwise_df = pd.DataFrame(index=index)\n",
    "pairwise_df['mi'] = pairwise_df.index.map(ranked_mi)\n",
    "pairwise_df['chi2'] = pairwise_df.index.map(ranked_chi2)\n",
    "pairwise_df['anova'] = pairwise_df.index.map(ranked_anova)\n",
    "pairwise_df['svm'] = pairwise_df.index.map(ranked_svm)\n",
    "\n",
    "pairwise_df.to_csv(f'results/{species}_{drug}/{species}_{drug}_pairwise_ARGs.csv')\n",
    "pairwise_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bet_cen = nx.betweenness_centrality(G)\n",
    "weighted_bet_cen = nx.betweenness_centrality(G, weight='weight')\n",
    "close_cen = nx.closeness_centrality(G)\n",
    "weighted_close_cen = nx.closeness_centrality(G, distance='weight')\n",
    "eigen_cen = nx.eigenvector_centrality(G)\n",
    "page_rank = nx.pagerank(G)\n",
    "degree_cen = nx.degree_centrality(G)\n",
    "weighted_degree_cen = nx.degree_centrality(G)\n",
    "\n",
    "clustering_coef = nx.clustering(G)\n",
    "\n",
    "ranked_bet_cen = gene_associations.get_ranked_ARGs_from_association(bet_cen, ARG_products_list, n=1000)\n",
    "ranked_weighted_bet_cen = gene_associations.get_ranked_ARGs_from_association(weighted_bet_cen, ARG_products_list, n=1000)\n",
    "ranked_close_cen = gene_associations.get_ranked_ARGs_from_association(close_cen, ARG_products_list, n=1000)\n",
    "ranked_weighted_close_cen = gene_associations.get_ranked_ARGs_from_association(weighted_close_cen, ARG_products_list, n=1000)\n",
    "ranked_eigen_cen = gene_associations.get_ranked_ARGs_from_association(eigen_cen, ARG_products_list, n=1000)\n",
    "ranked_page_rank = gene_associations.get_ranked_ARGs_from_association(page_rank, ARG_products_list, n=1000)\n",
    "ranked_degree_cen = gene_associations.get_ranked_ARGs_from_association(degree_cen, ARG_products_list, n=1000)\n",
    "ranked_weighted_degree_cen = gene_associations.get_ranked_ARGs_from_association(weighted_degree_cen, ARG_products_list, n=1000)\n",
    "ranked_clustering_coef = gene_associations.get_ranked_ARGs_from_association(clustering_coef, ARG_products_list, n=1000)\n",
    "\n",
    "ranked_bet_cen = flip_dict(ranked_bet_cen)  # -- to get the ARGs as keys\n",
    "ranked_weighted_bet_cen = flip_dict(ranked_weighted_bet_cen)\n",
    "ranked_close_cen = flip_dict(ranked_close_cen)\n",
    "ranked_weighted_close_cen = flip_dict(ranked_weighted_close_cen)\n",
    "ranked_eigen_cen = flip_dict(ranked_eigen_cen)\n",
    "ranked_page_rank = flip_dict(ranked_page_rank)\n",
    "ranked_degree_cen = flip_dict(ranked_degree_cen)\n",
    "ranked_weighted_degree_cen = flip_dict(ranked_weighted_degree_cen)\n",
    "ranked_clustering_coef = flip_dict(ranked_clustering_coef)\n",
    "\n",
    "index = ARG_products_list_in_pan\n",
    "net_df = pd.DataFrame(index=index)\n",
    "\n",
    "net_df['betweenness'] = net_df.index.map(ranked_bet_cen)\n",
    "net_df['weighted_betweenness'] = net_df.index.map(ranked_weighted_bet_cen)\n",
    "net_df['closeness'] = net_df.index.map(ranked_close_cen)\n",
    "net_df['weighted_closeness'] = net_df.index.map(ranked_weighted_close_cen)\n",
    "net_df['eigenvector'] = net_df.index.map(ranked_eigen_cen)\n",
    "net_df['page_rank'] = net_df.index.map(ranked_page_rank)\n",
    "net_df['degree'] = net_df.index.map(ranked_degree_cen)\n",
    "net_df['weighted_degree'] = net_df.index.map(ranked_weighted_degree_cen)\n",
    "net_df['clustering_coef'] = net_df.index.map(ranked_clustering_coef)\n",
    "\n",
    "net_df.to_csv(f'results/{species}_{drug}/{species}_{drug}_network_centralities_ARGs.csv')\n",
    "net_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ranked_mi)\n",
    "print(ranked_chi2)\n",
    "print(ranked_anova)\n",
    "print(ranked_svm)\n",
    "print(ranked_bet_cen)\n",
    "print(ranked_weighted_bet_cen)\n",
    "print(ranked_close_cen)\n",
    "print(ranked_weighted_close_cen)\n",
    "print(ranked_eigen_cen)\n",
    "print(ranked_page_rank)\n",
    "print(ranked_degree_cen)\n",
    "print(ranked_weighted_degree_cen)\n",
    "print(ranked_clustering_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([pairwise_df, net_df], axis=1)\n",
    "df.to_csv(f'results/{species}_{drug}/{species}_{drug}_ARGs_all.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --betweenness\n",
    "bet = nx.betweenness_centrality(G, weight='weight')\n",
    "gene_associations.get_ranked_ARGs_from_association(bet, ARG_products_list, n=len(nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --closeness\n",
    "clo = nx.closeness_centrality(G, distance='weight')\n",
    "gene_associations.get_ranked_ARGs_from_association(clo, ARG_products_list, n=len(nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weightd_deg = dict(G.degree(weight='weight'))\n",
    "gene_associations.get_ranked_ARGs_from_association(weightd_deg, ARG_products_list, n=len(nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigen = nx.eigenvector_centrality(G, weight='weight')\n",
    "gene_associations.get_ranked_ARGs_from_association(eigen, ARG_products_list, n=len(nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.set_node_attributes(G, lor_resistance_scores_dict, f'log_odds_{drug}_resistance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.nodes(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cluster_analysis\n",
    "cluster_info_df = pd.read_csv(f'data/clusters/{species}_cluster_info_filtered.csv', index_col=0)\n",
    "G = cluster_analysis.set_node_attributes_by_cluster(cluster_info_df, G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.nodes(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_graphml(G,f'results/Escherichia_coli_ampicillin/{species}_{drug}_LOR_annotated.graphml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "louvain_com = nx.algorithms.community.louvain_communities(G, weight='weight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "louvain_com\n",
    "# check log_odds distribution of the communities\n",
    "for community in louvain_com:\n",
    "    com_nodes_lor = []\n",
    "    for node in louvain_com[community]:\n",
    "        com_nodes_lor.append(G.nodes[node][f'log_odds_{drug}_resistance'])\n",
    "    print(f'community {community} log_odds distribution:')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
